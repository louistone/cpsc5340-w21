{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "**Background explanation only -- delete before submitting the assignment**\n",
    "\n",
    "Boolean retrieval in one markdown cell\n",
    "\n",
    "The problem:  given a *search query* and a *document* answer whether or not a document *satisfies* the query.\n",
    "\n",
    "Equivalent:  given a *search query* and a *set of documents* return the subset of documents that  *satisfy* the query.\n",
    "\n",
    "Satisfaction is either true or false.  (So no notion of relevance or satisfying partially or more.)\n",
    "\n",
    "A query is a boolean combination of *term matches*:\n",
    "```\n",
    "T1\n",
    "(NOT T1)\n",
    "(T1 OR T2)\n",
    "(T1 AND T2)\n",
    "```\n",
    "\n",
    "where T1 is a term, i.e. a word, i.e. a string of characters, and a document \n",
    "D\n",
    "is a set of terms, and the query is satisfied if and only if T1 appears in D\n",
    "\n",
    "Exact string match is a good start, but too strong\n",
    "* Case sensitive?  \"Hello\" should probably match \"hello\".  But should \"Apple\" match \"apple\"?\n",
    "* Punctuation?   \"Hello\" should probably match \"Hello!\". But should \"second-best\" be considered one term or two?\n",
    "* (Lots of others -- this is a big topic, but not for today!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assignment 0 -- TCSS 5910\n",
    "\n",
    "In this assignment you are going to read in some text files containing movie reviews and index them so you can perform boolean AND/OR queries.\n",
    "\n",
    "The directory **data** has one file per review.   The name of the file will act as the document ID, so for example the file **data/Dog4.txt** will have the Document ID **Dog4**.  The file contains the review text.\n",
    "\n",
    "The query operators will be \n",
    "* **query(term)** -- Term is a string, return a set of the IDs of all documents that contain it\n",
    "* **and_query(arg1, arg2)** -- The arguments are either strings or sets of document IDs.  Return a set of the IDs of the documents at the *intersection* of the two arguments\n",
    "* **or_query(arg1, arg2)** -- The arguments are either strings or sets of document IDs.  Return a set of the IDs of the documents at the *union* of the two arguments\n",
    "\n",
    "The more complicated definition of **and_query** and **or_query** is because we want to nest them.  For example:\n",
    "<pre>or_query('hello', 'world')</pre> and <pre>or_query('hello', or_query('world', 'earth'))</pre> both need to work.\n",
    "\n",
    "At the end of the exercise we want to see this:\n",
    "<pre>\n",
    "#  Query on a single term gives back a set of document IDs\n",
    "print(query('movie'))\n",
    "\n",
    "#  And query\n",
    "print(and_query('yellow', 'lab'))\n",
    "\n",
    "# Nested query\n",
    "print(and_query(and_query('salome', or_query('good', 'excellent')), 'opera'))\n",
    "\n",
    "# Too bad that or_query needs exactly two arguments!\n",
    "print(or_query(or_query('good', 'excellent'), or_query('liked', 'loved')))\n",
    "</pre>\n",
    "<pre>\n",
    "{'Dog4', 'Joe1', 'Dog3', 'Dog2', 'Dog1', 'Joe2'}\n",
    "{'Dog1', 'Dog2'}\n",
    "{'Salome5'}\n",
    "{'DooWop2', 'Dog4', 'Joe1', 'Joe2', 'Salome5', 'DooWop1'}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "\n",
    "\n",
    "#### Step 1:  Read in the review files, and for each get the doc ID and review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "#  Iterate over all the files in the data directory.  For each:\n",
    "#    -- extract its file basename as the docID\n",
    "#    -- read the file as a single string\n",
    "\n",
    "#  Return a dictionary of {docID: review_text} pairs, one for each file in the data directory\n",
    "def get_IDs_and_reviews():\n",
    "    dict = {}\n",
    "    # Iterate over the file names in DATA_DIR -- for each, read the review body;\n",
    "    #  add the docID and the review body to the dictionary\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        dict[getDocID(filename)] = readFile(filename)\n",
    "    return dict\n",
    "\n",
    "#  Return the name of the file in this path, without the directories and \n",
    "#  without the extension.  For example,   \"data/Dog1.txt\"  ->  \"Dog1\"\n",
    "#\n",
    "#  Hint: look at os.path.basename and os.path.splitext\n",
    "def getDocID(path):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# The filename is something like \"Dog1.txt\" -- open that file relative to DATA_DIR, \n",
    "#  read its contents as a string, and return that string\n",
    "\n",
    "# Hint.  the primitive open(filename) opens a file;  A file has a read() operation\n",
    "# that returns its contents as a string\n",
    "def readFile(filename):\n",
    "    #  YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bind a variable for later use, and make sure it has the expected contents\n",
    "ids_and_reviews = get_IDs_and_reviews()\n",
    "print(len(ids_and_reviews))\n",
    "print(ids_and_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some heavily edited output.  Notice that the reviews are pretty messy, they have newlines, HTML tags, mixed capitalization, etc.\n",
    "\n",
    "<pre>\n",
    "13\n",
    "{'Dog1': 'You don't have to own a Yellow Lab to absolutley love this movie, \\n but ...',  \n",
    " 'Dog2': '... mesmerized by this movie. &lt;em&gt;The adventures of a lost boy and dog&lt;/em&gt;....',\n",
    "   ...\n",
    " 'DooWop1':  'Excellent, excellent performers.  Excellent video and audio quality....', \n",
    " 'Salome5':  'I saw this production on TV many years ago and thought then that it was really ...'\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "\n",
    "####  Step 2: Cleaning up the review text\n",
    "\n",
    "Next we want to do some basic cleanup:  tokenize the input into individual words, get rid of special characters, \n",
    "get rid of HTML tags etc.\n",
    "\n",
    "Result will be the same dictionary as before, except the review text will be a list of strings (we call the 'tokens'), not a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#  This should return a list of strings, every string should be all lower-case letters\n",
    "\n",
    "# Hint:  \n",
    "#    the word_tokenize function in nltk.tokenize will split the string into tokens\n",
    "#    the string method lower() converts a string to all lower case\n",
    "#    the string method isalpha() returns true if the string is all letters \n",
    "def clean_review(review):\n",
    "    #  YOUR CODE HERE\n",
    "\n",
    "# Notice this function side-effects its input arguments\n",
    "def clean_reviews(id_to_reviews):\n",
    "    for docID, review in id_to_reviews.items():\n",
    "        id_to_reviews[docID] = clean_review(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews(ids_and_reviews)\n",
    "print(ids_and_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all special characters have been removed, the words are all letters, and all in lower case.\n",
    "Removing all special characters might be too extreme in a real system, for example our code will remove *don't* and *well-made* -- but it's simple and good enough for now.\n",
    "\n",
    "<pre>\n",
    "{'Dog1': ['you', 'do', 'have', 'to', 'own', 'a', 'yellow', 'lab', ...],\n",
    " 'Dog3': ['you', 'do', 'have', 'to', 'be', 'a', 'kid', 'to', 'enjoy', ...],\n",
    " 'Joe1': ['i', 'not', 'a', 'tim', 'allen', 'fan', 'i', 'had', 'only', 'watched', ...],\n",
    "  ... \n",
    " 'Salome5': ['i', 'saw', 'this', 'production', 'on', 'tv', 'many', 'years', 'ago',...]}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "####  Step 3:  Build the document-to-term dictionaries\n",
    "\n",
    "In this step we convert the list of words to a dictionary:  the key is a string (term/token/word) and the value is a set containing exactly one docID.\n",
    "\n",
    "For example in the output above we should get a dictionary that looks like this, partially\n",
    "<pre>\n",
    "{ 'you': {'Dog1'},\n",
    "  'do':  {'Dog1},\n",
    "  'have': {'Dog1} ...\n",
    " }\n",
    "</pre>\n",
    "\n",
    "This is the dictionary only for the first document/review -- we will have a different dictionary for each of the 13 reviews.\n",
    "\n",
    "The dictionary's value is always a set with one element, and the one element will be the same for each review -- the docID for that review.  It has that format so next we can merge all of the 13 dictionaries to get a single dictionary of a term to the IDs of all the documents that contain that term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Input is a dictionary docID -> termList\n",
    "#  Output is a list of dictionaries, one per review, each of the form   term -> {docID}\n",
    "\n",
    "# Hint:\n",
    "#  if the variable docID is a string, then {docID} creates a set containing just that string\n",
    "#  To iterate over the key/value pairs in a dictionary, use   \n",
    "#      for docID, terms in docs_to_terms.items():\n",
    "\n",
    "def build_term_to_doc_dictionaries(docs_to_terms):\n",
    "    dd = []\n",
    "    #  YOUR CODE HERE\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_to_doc = build_term_to_doc_dictionaries(ids_and_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of 13 dictionaries.  Each dictionary has keys which are terms, and a value which is a set containing exactly one document ID\n",
    "\n",
    "<pre>\n",
    "[{'you': {'Dog1'},\n",
    "  'do': {'Dog1'},\n",
    "  'have': {'Dog1'},\n",
    "  ...\n",
    "  }, \n",
    " {'as': {'Dog2'},\n",
    "  'owners': {'Dog2'},\n",
    "\n",
    "  'wildlife': {'Dog4'},\n",
    "  'wolves': {'Dog4'},\n",
    "  'wild': {'Dog4'},\n",
    "  'cats': {'Dog4'},\n",
    "  ...\n",
    "  },\n",
    "  ...\n",
    " {'excellent': {'DooWop1'},\n",
    "  'performers': {'DooWop1'},\n",
    "  ...\n",
    "  },\n",
    "  ...\n",
    "  ]\n",
    " </pre>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "\n",
    "#### Step 4:  Merge Term to Doc ID \n",
    "\n",
    "This is the last preprocessing step -- we need to merge these 13 term to document dictionaries into a single dictionary that looks like:   \n",
    "<pre>\n",
    "term: {docID1, docID2, ...} \n",
    "</pre>\n",
    "in other words, for every term that appears in *any* document, a set/list of the documents containing it.\n",
    "\n",
    "This step is a little tricky because if I want to merge two dictionaries *d1* and *d2* there will be some terms that appear in *d1* but not *d2*, some that appear in *d2* but not *d1*, and some that appear in both.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary that has keys that are the union of d1's and d2's keys \n",
    "# and whose value for each key is a set which is the union of d1's and d2's values\n",
    "# for that key.   If a key is not in d1's or d2's dictionary, its value for that \n",
    "# key should be interpreted as the empty set.\n",
    "\n",
    "# Hint -- start by getting all the terms --     \n",
    "#   allTerms = set(d1.keys()) | set(d2.keys())\n",
    "\n",
    "def merge_two(d1, d2):\n",
    " # YOUR CODE HERE\n",
    "\n",
    "# Merge a list of indexes sequentially\n",
    "def merge_indexes(indexes):\n",
    "    dout = {}\n",
    "    for d in indexes:\n",
    "        dout = merge_two(dout, d)\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_to_docs = merge_indexes(term_to_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(term_to_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is edited output, so yours won't be in this order, though the values should be the same.\n",
    "\n",
    "This is the inverted index we will query against.   Note that there are some useless words like 'with' and 'while' that probably should be excluded.  These are known as *stop words* \n",
    "\n",
    "<pre>\n",
    "{ 'comforts': {'Dog4'}, \n",
    "  'about': {'Salome1'}, ...\n",
    "  'first': {'DooWop2', 'Joe2', 'Salome2'}, \n",
    "  'with': {'DooWop2', 'Dog4', 'Joe1', 'Salome5', 'Salome2', 'Dog3', 'Salome1', 'Joe2', 'Salome4', 'Salome3'}, \n",
    "  'thought': {'DooWop2', 'Salome5'}, \n",
    "  'buy': {'DooWop1', 'Dog2', 'Salome1'}, \n",
    "  'while': {'DooWop2', 'Dog4', 'Dog1', 'Salome1', 'Salome4'}, \n",
    "  ...\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5:  Queries\n",
    "\n",
    "Now it's easy to do queries on the index\n",
    "\n",
    "* for a simple query (single term) just look up the term in the index and retrieve its doc IDs\n",
    "* for an AND query, take the intersection of the doc IDs\n",
    "* for an OR query, take the union of the doc IDs\n",
    "\n",
    "The complication is that in order to do nesting, *and_query* and *or_query* need to accept either a term (string) or a set of docIDs as input.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that we are assuming a global variable here.  Messy! \n",
    "INVERTED_INDEX = term_to_docs\n",
    "\n",
    "# Access INVERTED_INDEX to get the docIDs for this term. \n",
    "# If the term is not in the index, return empty set\n",
    "def query(term):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# If either or both arguments are strings, first call query() to get a set of doc IDs.\n",
    "#  Once both arguments are sets, just return the intersection of the sets.\n",
    "\n",
    "def and_query(term1, term2):\n",
    "    #  YOUR CODE HERE\n",
    "\n",
    "def or_query(term1, term2):\n",
    "    #  YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Query on a single term gives back a set of document IDs\n",
    "print(query('movie'))\n",
    "\n",
    "#  And query\n",
    "print(and_query('yellow', 'lab'))\n",
    "\n",
    "# Nested query\n",
    "print(and_query(and_query('salome', or_query('good', 'excellent')), 'opera'))\n",
    "\n",
    "# Too bad that or_query needs exactly two arguments!\n",
    "print(or_query(or_query('good', 'excellent'), or_query('liked', 'loved')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "{'Dog4', 'Dog3', 'Dog2', 'Dog1', 'Joe1', 'Joe2'}\n",
    "{'Dog1', 'Dog2'}\n",
    "{'Salome5'}\n",
    "{'DooWop2', 'Dog4', 'Joe1', 'Joe2', 'Salome5', 'DooWop1'}\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
