{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "\n",
    "If the IR cycle is something like this:\n",
    "1. Collect documents (i.e. web crawling or retrieving specific pages)\n",
    "1. Extract *structured* information from documents (i.e. convert the document external format to match your schema)\n",
    "1. Index the documents\n",
    "1. Query the index\n",
    "\n",
    "Most of the documents of interest have some structured elements and some unstructured elements. \n",
    "We will look at Seattle U computer science faculty home pages.  For example, Prof. Dingle's page:\n",
    "https://www.seattleu.edu/scieng/computer-science/faculty-and-staff/dingle-adair.html\n",
    "\n",
    "Things like the name, email, office number, and phone number are structured, and the list of research interests is (probably) unstructured narrative. \n",
    "\n",
    "Here we are going to concentrate on the first two.  We will work on\n",
    "1. Making a service call to get an HTML document\n",
    "1. Parsing the document to pull out certain fields \n",
    "1. Packaging and storing document data so it's ready for indexing\n",
    "\n",
    "The exercise:  for any/all faculty pages, extract this information\n",
    "\n",
    "1. Name\n",
    "1. Phone number\n",
    "1. Email address\n",
    "1. Research interests\n",
    "\n",
    "Many sites have a \"structured API\"  -- for example https://docs.microsoft.com/en-us/linkedin/ -- which takes a request (e.g. for a person or handle) and returns a data structure (e.g. containing the person's name, contacts, employment history).  \n",
    "But sometimes we have to extract structured information directly from a web page -- that is tricky and dangerous, because the HTML is structured for display purposes and not semantically -- the HTML can change abruptly and break all your extraction code, and there is no guarantee that the structure of every page of interest is the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Service Calls\n",
    "\n",
    "Getting the HTML source for a page.\n",
    "\n",
    "We will be making calls to an HTTP server, so we need to talk about requests and responses.  This will be useful to you both in the retrieval context, but also because you will be making requests to SOLR, which is itself a service.\n",
    "\n",
    "We will use Python requests library http://docs.python-requests.org/en/master/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.seattleu.edu/scieng/computer-science/faculty-and-staff/dingle-adair.html\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML String to Parsed HTML\n",
    "\n",
    "Beautiful Soup package\n",
    "* Documentation:  https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "* Installation: pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = soup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This extracts the name!\n",
    "page.find('div', {'id': 'zoneA'}).find('h1', {'id': 'pageTitle'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This extracts the email!!\n",
    "page.find('div', {'id': 'zoneA'}).\\\n",
    "find('div', {'class': \"staffBioPageInfo\"}).\\\n",
    "find('p', {'class': 'Email'}).\\\n",
    "find('a').\\\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This extracts the phone!!\n",
    "page.find('div', {'id': 'zoneA'}).\\\n",
    "find('div', {'class': \"staffBioPageInfo\"}).\\\n",
    "find('p', {'class': 'Phone'}).\\\n",
    "text.replace('Phone: ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This extracts the bio information!!!\n",
    "page.find('div', {'class': \"ExtendedBiography\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packaging it Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = ['dingle-adair', \n",
    "           'mckee-michael', \n",
    "           'hanks-steven', \n",
    "           'khadivi-pejman', \n",
    "           'leblanc-richard', \n",
    "           'koenig-michael',\n",
    "          'kong-hidy',\n",
    "          'larson-eric',\n",
    "          'li-lin',\n",
    "          'lundeen-kevin',\n",
    "          'mishra-aditya',\n",
    "          'obare-james',\n",
    "          'oh-sheila',\n",
    "          'reeder-susan',\n",
    "          'wong-jason',\n",
    "          'zhu-yingwu-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "r = list(range(1990, 2020))\n",
    "choice(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def choose_joined_year():\n",
    "    return choice(list(range(1995, 2015))) \n",
    "\n",
    "def extract_faculty_info(handle):\n",
    "    url = f\"https://www.seattleu.edu/scieng/computer-science/faculty-and-staff/{handle}.html\"\n",
    "    response = requests.get(url)\n",
    "    page = soup(response.text, \"html.parser\")\n",
    "    name = page.find('div', {'id': 'zoneA'}).find('h1', {'id': 'pageTitle'}).text\n",
    "    email = page.find('div', {'id': 'zoneA'}).find('div', {'class': \"staffBioPageInfo\"}).find('p', {'class': 'Email'})\n",
    "    if email == None:\n",
    "        email = None\n",
    "    else:\n",
    "        email = email.find('a').text\n",
    "    phone = page.find('div', {'id': 'zoneA'}).find('div', {'class': \"staffBioPageInfo\"}).find('p', {'class': 'Phone'})\n",
    "    if phone == None:\n",
    "        phone = None\n",
    "    else:\n",
    "        phone = phone.text.replace('Phone: ', '')\n",
    "    bio = page.find('div', {'class': \"ExtendedBiography\"})\n",
    "    if bio == None:\n",
    "        bio = None\n",
    "    else:\n",
    "        bio = bio.text\n",
    "    return {'name': name, 'email': email, 'phone': phone, 'bio': bio, 'joined': choose_joined_year(), \"handle\": handle}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adair Dingle, Ph.D.', 'email': 'dingle@seattleu.edu', 'phone': '(206) 296-5516', 'bio': \"Dr. Dingle's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nData Structures\\nFoundations of Computer Science\\nObject-Oriented Software Development\\nLanguages and Computation\\nDesign Patterns and Refactoring\\n\\n\\xa0\\nResearch Interests:\\nReclaiming Garbage and Education: Java Memory Leaks, Tracking the Design of Objects: Encapsulation Through Polymorphism, The Maintainability Gap, Assessing the Ripple Effect of Language Choice in CS1, Improving C++ Performance Using Temporaries, The Object-Ownership Model: A Case Study for Inheritance and Operator Overloading\", 'joined': 2011, 'handle': 'dingle-adair'}\n",
      "{'name': 'Michael McKee', 'email': 'mckeem@seattleu.edu', 'phone': None, 'bio': '\\xa0\\nTeaching Interests:\\n\\nProgramming & Problem Solving\\nData Structures And Algorithms\\nDatabases\\nSoftware Economics\\nSoftware Testing\\nData Analytics\\n\\nResearch Interests:\\n\\nCS Education, Databases, Data Warehousing, Computer Languages, Economics, STEM.\\n', 'joined': 2009, 'handle': 'mckee-michael'}\n",
      "{'name': 'Steven Hanks, Ph.D.', 'email': 'hankssteven@seattleu.edu', 'phone': None, 'bio': '\\xa0\\nTeaching interests:\\n\\nData science\\nArtificial intelligence\\nSoftware design\\nText and natural language processing, and search\\n\\nResearch interests:\\n\\nApplication of data-science methodologiesConnecting machine learning and AI – how ML algorithms can learn representations useful for “general commonsense intelligence” (whatever that means)\\xa0\\n', 'joined': 1997, 'handle': 'hanks-steven'}\n",
      "{'name': 'Pejman Khadivi, Ph.D.', 'email': 'khadivip@seattleu.edu', 'phone': '(206) 296-2567', 'bio': \"Dr. Khadivi's Personal Web Page\\n\\xa0\\nTeaching Interests:\\n\\nDesign & Analysis of Algorithm\\nComp Systems Principles\\nArtificial Intelligence\\n\\n\\xa0\\nResearch Interests:\\nMy primary research interests are in the field of artificial intelligence, machine learning, and data analytics using large scale datasets, with emphasis on time series analytics, which is considered as a critical component in various domains including forecasting, cyber-physical systems, anomaly detection, and reliable system design.\\nIn cyber-physical systems, beside forecasting and prediction tasks, machine learning techniques can be used in other applications such as anomaly detection, smart controller design, and surveillance systems. Furthermore, one of the important issues with machine learning and time series analytics is the existence of noise in datasets. Machine learning algorithms are sensitive to noise and hence, denosing is a crucial step to perform before using any machine learning algorithm. Current research problems that I am working on them are as follows:\\n\\nReal time techniques for time series denoising using information theory and deep learning\\nAnomaly detection in cyber-physical systems in order to perform fault detection and fault location with the aim of reliability improvement\\nUsing open source datasets for forecasting applications in health science and tourism industry\\nWikipedia usage behavior modeling\\n\\n\\xa0\\n\\xa0\", 'joined': 2004, 'handle': 'khadivi-pejman'}\n",
      "{'name': 'Richard Leblanc, Ph.D.', 'email': 'leblanc@seattleu.edu', 'phone': '(206) 296-5511', 'bio': '\\xa0\\nTeaching Interests:\\n\\nLanguages and Computation\\nTech Comm & Proj Management\\nEthics & Prof Iss in Computing\\n\\n\\xa0\\nRecent Publications:\\n\\nCrafting the Future of Software Engineering Education in CC2020: A WorkshopRJ LeBlanc, NR Mead, J ImpagliazzoSoftware Engineering Education and Training (CSEE&T), 2017 IEEE 30th … 2017\\nIEEE 27th Conference on Software Engineering Education and Training (CSEE&T)A Bollin, E Hochmüller, RT Mittermeir, T Cowling, R LeBlanc 2014\\nACM/IEEE-CS computer science curricula 2013: implementing the final reportM Sahami, S Roach, E Cuadros-Vargas, EK Hawthorne, A Kumar, ...Proceedings of the 45th ACM technical symposium on Computer science ... 2014\\nSpecial session: The CS2013 Computer Science curriculum guidelines projectS Roach, M Sahami, R LeBlanc, R SekerFrontiers in Education Conference, 2013 IEEE, 1311-1313 1 2013\\nSoftware engineering in CS 2013R LeBlancSoftware Engineering Education and Training (CSEE&T), 2013 IEEE 26th … 2013\\nAcm/ieee-cs computer science curriculum 2013: Reviewing the ironman reportM Sahami, S Roach, E Cuadros-Vargas, R LeBlancProceeding of the 44th ACM technical symposium on Computer science education … 2013\\nExploring the Computer Science 2013 Curriculum GuidelinesR LeBlanc, M BarkerSoftware Engineering Education and Training (CSEE&T), 2012 IEEE 25th … 2012\\n', 'joined': 2002, 'handle': 'leblanc-richard'}\n",
      "{'name': 'Michael Koenig', 'email': 'koenigm@seattleu.edu', 'phone': '(206) 296-2568', 'bio': '\\xa0\\nTeaching Interests:\\n\\nFundamentals Of Software Engineering\\nSeminar\\nMobile App Development\\n', 'joined': 1996, 'handle': 'koenig-michael'}\n",
      "{'name': 'Hidy Kong, Ph.D.', 'email': 'hkong@seattleu.edu', 'phone': '(206) 296-5562', 'bio': \"Dr. Kong's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nData Structures\\nVisual Analytics\\n\\nResearch Interests:\\nMy research interests are in Human Computer Interaction (HCI) and visualization. My current projects focus on people’s perceptions and usage of data visualization in various domains including healthcare and the media.\\nRecently, I have studied credibility and trust in visualization online, and examined the role of textual components in information recall and trust. I also built and evaluated visualization webtools to help clinicians and parents of young children communicate more efficiently.\", 'joined': 1998, 'handle': 'kong-hidy'}\n",
      "{'name': 'Eric Larson, Ph.D.', 'email': 'elarson@seattleu.edu', 'phone': '(206) 296-5513', 'bio': \"Dr. Larson's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nFoundations of Computer Science\\nLanguages and Computation\\nComputing Systems\\n\\n\\xa0\\nResearch Interests:\\nSoftware bug detection and software testing. My current project focuses on finding bugs within regular expressions using a combination of test generation and static bug detection techniques.\", 'joined': 2006, 'handle': 'larson-eric'}\n",
      "{'name': 'Lin Li, Ph.D.', 'email': 'lil@seattleu.edu', 'phone': '(206) 296-2112', 'bio': \"Dr. Li's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nProgramming and Data Types\\nFundamentals of Databases\\nDatabase Systems\\nData Science\\n\\n\\xa0\\nResearch Interests:\\nMy research focuses on medical imaging, medical image analysis using machine learning, and computer-aided diagnosis. I have been primarily working on three research projects since joining SU:\\n\\nNon-invasive skin cancer detection using computer-aided spectroscopic systems;\\nPrediction of blood glucose level and detection of hyperglycemia/hypoglycemia using optimization and machine learning techniques;\\nDetection of diabetic retinopathy of diabetic patients using image processing and machine learning techniques.\\n\\nIn the meanwhile, I have been also working on some research projects related to machine learning - for example, how to adjust weight of single classifier in an ensemble of classifiers for classification problems and regression problems.\\xa0\\n\\xa0\", 'joined': 1996, 'handle': 'li-lin'}\n",
      "{'name': 'Kevin Lundeen\\n', 'email': 'lundeenk@seattleu.edu', 'phone': '(206) 296-2333', 'bio': '\\xa0\\nTeaching Interests:\\n\\nData-Driven Programming\\nProgramming & Prob Solving\\nData Structures\\nProgramming Boot Camp\\nData Structures And Algorithms\\nPhysical Databases\\n\\n\\xa0\\nResearch Interests:\\nCS Education, Databases, Computer Languages, Distributed Computing, Finance and Medical Applications.', 'joined': 2003, 'handle': 'lundeen-kevin'}\n",
      "{'name': 'Aditya Mishra, Ph.D.', 'email': 'mishraa@seattleu.edu', 'phone': '(206) 296-2570', 'bio': \"Dr. Mishra's Personal Webpage\\n\\xa0\\n\\xa0\\nTeaching Interests:\\n\\nData Structures\\nComputer Organization\\nComp Systems Principles\\nComputer Architecture\\xa0\\n\\n\\xa0\\nGeneral Research Interests:\\nMy research has broadly focused on sustainability in smart grids and Internet networks. In smart grids, we have been working on designing techniques for integrating renewable energy in building consumption to cut their electricity bills, grid consumption, demand peaks, and make their consumption profile more grid-friendly and sustainable. In the area of large-scale networks, we have devised novel traffic engineering algorithms to improve resource utilization in Internet backbone networks.\\n\\xa0\\n\\xa0\", 'joined': 2002, 'handle': 'mishra-aditya'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'James Obare', 'email': 'obarej@seattleu.edu', 'phone': '(206) 296-2837', 'bio': '\\xa0\\nTeaching Interests:\\n\\nIntro to Computer Science\\nIntro Computers & Applications\\nComp Systems Principles\\nCyber Security\\nComputer Organization and Architecture\\n', 'joined': 1998, 'handle': 'obare-james'}\n",
      "{'name': 'Sheila Oh', 'email': 'ohsh@seattleu.edu', 'phone': '(206) 296-2164', 'bio': \"Professor Oh's Personal Webpage\\xa0\\n\\xa0\\nTeaching Interests:\\n\\nProgramming & Prob Solving\\nFoundations of Computer Sci\\nFundamentals of Databases\\nObject-Oriented Concepts\\nDatabase Systems\\nData Structures And Algorithms\\n\", 'joined': 2012, 'handle': 'oh-sheila'}\n",
      "{'name': 'Susan Reeder', 'email': 'sreeder@seattleu.edu', 'phone': '(206) 296-5508', 'bio': \"Professor Reeder's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nProgramming and Data Types\\nProgramming & Prob Solving\\nData Structures, Object-Oriented Development\\nThe Art of Web Design\\n\", 'joined': 2005, 'handle': 'reeder-susan'}\n",
      "{'name': 'Jason Wong', 'email': 'wongja@seattleu.edu', 'phone': '(206) 296-5949', 'bio': '\\xa0\\nTeaching Interests:\\n\\nFundamentals of Databases\\nSoftware Engineering & Project Development\\nSecurity in Computing\\n\\n\\xa0\\nCurrent Interests:\\nI am responsible for coordinating the senior and graduate computer science capstone projects. In this role I work with industry and community organizations to scope software projects that students must complete to fulfill their academic requirements. I also serve as a faculty advisor to a number of these projects.\\nPrior to joining Seattle University, I worked in the technology industry for 30 years primarily in M&A, consulting and IT.', 'joined': 2000, 'handle': 'wong-jason'}\n",
      "{'name': 'Yingwu Zhu, Ph.D.', 'email': 'zhuy@seattleu.edu', 'phone': '(206) 296-5515', 'bio': \"Dr. Zhu's Personal Webpage\\n\\xa0\\nTeaching Interests:\\n\\nData Structures and Algorithms\\nComputing Systems\\nComputer Networks\\nDistributed Systems\\n\\n\\xa0\\nResearch Interests:\\nDr. Yingwu Zhu's research interests lie broadly in distributed systems and computer networks. In particular, his recent research projects focus on peer-to-peer (P2P) video on demand (VoD), P2P continuous query, cloud computing, social networks, Internet congestion, and Internet of Things (IoT). He has published about 50 papers on many premier peer-reviewed journals and conferences, including IEEE Transactions on Parallel and Distributed Systems (TPDS), IEEE Transactions on Computers (TOC), Journal of Parallel and Distributed Computing (JPDC), IEEE International Parallel & Distributed Processing Symposium (IPDPS), International World Wide Web Conference (WWW), International Conference on Parallel Processing (ICPP), International\\xa0 Conference on Distributed Computing Systems (ICDCS), and IEEE Symposium on Reliable Distributed Systems (SRDS), to name a few. Some of his publications have received more than a hundred citations.\\n\\xa0\", 'joined': 2007, 'handle': 'zhu-yingwu-'}\n"
     ]
    }
   ],
   "source": [
    "for handle in handles:\n",
    "    print(extract_faculty_info(handle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializing / Storing\n",
    "\n",
    "It is often useful/necessary to store these \"documents\" prior to indexing.  Usually this consists of storing the URL or handle, and have it point to the parsed document.   That way a crawler can skip the page if it wants\n",
    "\n",
    "Two implementations\n",
    "* Quick and easy and efficient:  python \"pickle\" serializer.\n",
    "* Stil quick and easy to use but leaves us readable text for indexing:  write JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dingle = extract_faculty_info('dingle-adair')\n",
    "pickle.dump(dingle, open(\"stored/dingle-adair.p\", \"wb\"))\n",
    "recovered = pickle.load( open( \"stored/dingle-adair.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put some aside for next lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for handle in handles:\n",
    "    data = extract_faculty_info(handle)\n",
    "    print(str(data) + \"\\n\")\n",
    "    pickle.dump(data, open( f\"stored/{handle}.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also put out a plain text version so we can use non-python tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_faculty_info('dingle-adair')\n",
    "str(data)\n",
    "f = open(\"json\\dingle-adair.json\", \"w\")\n",
    "f.write(str(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for handle in handles:\n",
    "    data = extract_faculty_info(handle)\n",
    "    with open(f\"json/{handle}.json\", \"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
